# Описание реализации

## Обзор решения

Реализован сервис отчётов для системы BionicPRO, который позволяет пользователям получать данные о работе своих протезов. Решение включает ETL-процесс, OLAP базу данных, API сервис и UI компонент.

## Компоненты системы

### 1. ETL-процесс (Apache Airflow)

**Файл**: `Task2/airflow/dags/prosthesis_reports_etl.py`

**Функциональность**:
- Извлечение данных о клиентах из CRM (PostgreSQL)
- Извлечение данных телеметрии из БД (PostgreSQL)
- Объединение и агрегация данных по пользователям и протезам
- Загрузка агрегированных данных в витрину ClickHouse

**Расписание**: Ежедневно в 02:00 UTC

**Метрики агрегации**:
- Количество использований протеза
- Общее время использования (в минутах)
- Средний уровень заряда батареи
- Количество выполненных команд

### 2. Витрина данных (ClickHouse)

**Таблица**: `user_prosthesis_reports`

**Структура**:
- Партиционирование по месяцам для быстрого доступа
- Сортировка по `(user_id, prosthesis_id, report_date)`
- Хранение периода данных для валидации запросов

**Оптимизация**:
- Использование движка MergeTree для эффективного хранения
- Индексы создаются автоматически на основе ORDER BY
- Поддержка быстрых запросов по user_id

### 3. API сервис (bionicpro-reports)

**Технологии**: Java 17, Spring Boot 3.2.0

**Эндпоинты**:
- `GET /api/reports` - получение отчёта текущего пользователя
  - Query параметры: `startDate`, `endDate` (опционально)
  - Авторизация: Bearer token (JWT)
  - Возвращает JSON с данными отчёта

**Безопасность**:
- JWT токен валидируется через фильтр `JwtAuthenticationFilter`
- Извлечение `user_id` из токена (поле `sub` или `preferred_username`)
- Проверка соответствия `user_id` в запросе и токене
- Возврат ошибок: 401 (не авторизован), 403 (доступ запрещён), 404 (данные не найдены)

**Валидация периода**:
- Проверка, что данные за запрошенный период уже обработаны Airflow
- Если данные не обработаны, возвращается ошибка 404 с понятным сообщением

### 4. Frontend

**Компонент**: `ReportPage.tsx`

**Функциональность**:
- Кнопка "Download Report" для запроса отчёта
- Автоматическое получение access token через auth service
- Отправка запроса к API с токеном в заголовке Authorization
- Скачивание отчёта в формате JSON
- Обработка ошибок с отображением сообщений пользователю

## Поток данных

1. **Сбор данных**: Airflow DAG ежедневно извлекает данные из CRM и телеметрии
2. **Агрегация**: Данные объединяются и агрегируются по пользователям
3. **Загрузка**: Агрегированные данные загружаются в витрину ClickHouse
4. **Запрос**: Пользователь запрашивает отчёт через UI
5. **Авторизация**: Frontend получает токен и отправляет запрос к API
6. **Валидация**: API проверяет токен и извлекает user_id
7. **Получение данных**: API запрашивает данные из ClickHouse для конкретного user_id
8. **Возврат**: API возвращает отчёт в формате JSON

## Безопасность

### Авторизация
- Все запросы к API требуют валидного JWT токена
- Токен получается через сервис `bionicpro-auth`
- Токен валидируется на стороне API сервиса

### Изоляция данных
- Пользователь может получить только свой отчёт
- `user_id` извлекается из токена и используется для фильтрации данных
- Дополнительная проверка на уровне API предотвращает доступ к чужим данным

### Валидация периода
- API проверяет, что запрашиваемый период уже обработан
- Предотвращает запросы данных, которых ещё нет в системе

## Особенности реализации

### Извлечение user_id из токена

В `AuthService.validateTokenAndGetUserId()`:
- Декодируется payload JWT токена
- Парсится JSON с использованием Jackson
- Извлекается `user_id` из полей `sub`, `preferred_username` или `email`

**Примечание**: В production необходимо добавить проверку подписи токена через публичный ключ Keycloak.

### Обработка ошибок

API возвращает понятные сообщения об ошибках:
- 401: "No session found" или "Session expired"
- 403: "Access denied" - попытка доступа к чужим данным
- 404: "Data not available" - данные за период не обработаны
- 500: "Internal server error" - внутренняя ошибка сервера

### Оптимизация запросов

ClickHouse витрина оптимизирована для:
- Быстрого поиска по `user_id`
- Фильтрации по датам
- Агрегации данных

## Тестирование

### Ручное тестирование

1. Запустить все сервисы: `docker-compose up -d`
2. Запустить Airflow DAG вручную
3. Проверить данные в ClickHouse
4. Авторизоваться через UI
5. Запросить отчёт через UI
6. Проверить скачанный JSON файл

### Проверка безопасности

1. Попытка запроса без токена → 401
2. Попытка запроса с невалидным токеном → 401
3. Попытка запроса данных другого пользователя → 403
4. Запрос данных за период, который не обработан → 404

## Дальнейшие улучшения

1. **Валидация подписи JWT**: Добавить проверку подписи через публичный ключ Keycloak
2. **Кэширование**: Добавить кэширование отчётов для часто запрашиваемых периодов
3. **Экспорт в PDF**: Добавить генерацию PDF отчётов на сервере
4. **Мониторинг**: Добавить метрики и логирование для мониторинга системы
5. **Тесты**: Добавить unit и integration тесты

