# Архитектура решения для сервиса отчётов

## Общее описание

Решение для генерации отчётов о работе протезов состоит из следующих компонентов:

1. **ETL-процесс (Apache Airflow)** - извлекает данные из CRM и базы данных телеметрии, объединяет их и загружает в OLAP БД
2. **OLAP БД (ClickHouse)** - хранит агрегированные данные в витрине отчётности для быстрого доступа
3. **API сервис (bionicpro-reports)** - предоставляет REST API для получения отчётов пользователями
4. **Frontend** - интерфейс для запроса и скачивания отчётов

## Компоненты системы

### 1. Источники данных

#### CRM-система (PostgreSQL)
Хранит информацию о клиентах:
- ID пользователя
- Данные профиля
- Информация о протезах
- История заказов

#### База данных телеметрии (PostgreSQL)
Хранит данные с датчиков протезов:
- ID протеза
- Временные метки
- Данные с миодатчиков
- Команды актуаторов
- Статус батареи

### 2. ETL-процесс (Apache Airflow)

**DAG: `prosthesis_reports_etl`**

Процесс включает следующие этапы:

1. **Extract (Извлечение)**
   - Извлечение данных о клиентах из CRM
   - Извлечение данных телеметрии из БД
   - Фильтрация по периоду обработки

2. **Transform (Преобразование)**
   - Объединение данных телеметрии с данными клиентов
   - Агрегация данных по пользователям
   - Расчёт метрик:
     - Количество использований протеза
     - Среднее время работы
     - Статистика по командам
     - Статус батареи

3. **Load (Загрузка)**
   - Загрузка агрегированных данных в витрину ClickHouse
   - Обновление существующих записей
   - Инкрементальная загрузка (только новые данные)

**Расписание**: Ежедневно в 02:00 UTC

### 3. Витрина данных (ClickHouse)

**Таблица: `user_prosthesis_reports`**

Структура витрины:

```sql
CREATE TABLE user_prosthesis_reports (
    user_id String,
    prosthesis_id String,
    report_date Date,
    usage_count UInt32,
    total_usage_minutes UInt32,
    avg_battery_level Float32,
    commands_executed UInt32,
    last_activity DateTime,
    data_period_start DateTime,
    data_period_end DateTime,
    created_at DateTime DEFAULT now()
) ENGINE = MergeTree()
PARTITION BY toYYYYMM(report_date)
ORDER BY (user_id, prosthesis_id, report_date);
```

**Особенности**:
- Партиционирование по месяцам для быстрого доступа
- Сортировка по user_id, prosthesis_id, report_date
- Хранение периода данных для валидации запросов

### 4. API сервис (bionicpro-reports)

**Технологии**: Java, Spring Boot

**Эндпоинты**:

- `GET /api/reports` - получение отчёта текущего пользователя
  - Query параметры:
    - `startDate` (опционально) - начало периода
    - `endDate` (опционально) - конец периода
  - Авторизация: Bearer token
  - Валидация: проверка, что запрашиваются только данные текущего пользователя

**Безопасность**:
- Интеграция с bionicpro-auth для проверки сессии
- Валидация JWT токена из Keycloak
- Извлечение user_id из токена
- Проверка соответствия user_id в запросе и токене

**Обработка ошибок**:
- 401 - не авторизован
- 403 - попытка доступа к чужим данным
- 404 - данные за запрошенный период ещё не обработаны
- 500 - внутренняя ошибка

### 5. Frontend

**Компонент**: ReportPage (уже существует, требует доработки)

**Функциональность**:
- Кнопка "Download Report"
- Отображение статуса загрузки
- Обработка ошибок
- Скачивание отчёта в формате JSON/PDF

## Поток данных

```
[CRM PostgreSQL] ──┐
                   ├──> [Airflow DAG] ──> [ClickHouse Витрина]
[Telemetry DB] ───┘                              │
                                                   │
[Frontend] ──> [bionicpro-reports API] ────────────┘
```

## Безопасность

1. **Авторизация**: Все запросы к API требуют валидной сессии через bionicpro-auth
2. **Изоляция данных**: Пользователь может получить только свой отчёт
3. **Валидация периода**: API проверяет, что запрашиваемый период уже обработан Airflow
4. **HTTPS**: В production все соединения должны быть защищены

## Масштабируемость

- ClickHouse обеспечивает быстрый доступ к агрегированным данным
- Airflow позволяет масштабировать ETL-процессы
- API сервис может быть развёрнут в нескольких экземплярах
- Витрина данных оптимизирована для чтения

## Мониторинг

- Логирование всех операций ETL
- Мониторинг времени выполнения DAG
- Логирование запросов к API
- Метрики производительности ClickHouse

